{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import operator\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the data, output and challenge dataset path\n",
    "Data_Path = '/Users/bijayani/Documents/MS/SEM3/CMPE256/Project/spotify_million_playlist_dataset/data'\n",
    "Result_Path = '/Users/bijayani/Documents/MS/SEM3/CMPE256/Project/SmallerDataSet/TitleMatching/'\n",
    "Challenge_data = '/Users/bijayani/Documents/MS/SEM3/CMPE256/Project/spotify_million_playlist_dataset_challenge/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open a csv file in write mode.\n",
    "final_file = open(os.path.join(Result_Path, 'title_popularity_recs.csv'), 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized method is used to normal the titles of the playlist.\n",
    "def normalize_title(title):\n",
    "    title = title.lower()\n",
    "    title = re.sub(r\"[.,\\/#!$%\\^\\*;:{}=\\_`~()@]\", ' ', title)\n",
    "    title = re.sub(r'\\s+', ' ', title).strip()\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the challenge dataset!\n",
    "\n",
    "#Creating a set for storing the challenge dataset playlist title.\n",
    "cold_start_titles = set()\n",
    "\n",
    "#load the challenge dataset\n",
    "f = open(os.path.join(Challenge_data, \"challenge_set.json\"))\n",
    "js = f.read()\n",
    "challenge_set = json.loads(js)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for the playlist that has 0 seed tracks. Those playlist will be cold start titles.\n",
    "for playlist in challenge_set['playlists']:\n",
    "    if playlist['num_samples'] < 1:\n",
    "        title = normalize_title(playlist['name'])\n",
    "        cold_start_titles.add(title)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the mdp data slices\n",
    "filenames = os.listdir(Data_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionary to save the titles\n",
    "title_dict = dict()\n",
    "final_dict = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pid_playlistName list to save the pid and titles of mdp datset.\n",
    "Pid_playListName =  []\n",
    "for filename in sorted(filenames):\n",
    "        #Fetching the mdp data.\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((Data_Path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            slice = json.loads(js)\n",
    "            \n",
    "            #Fetching each playlist from the mdp data file.\n",
    "            for playlist in slice['playlists']:\n",
    "                #Extracing the playlistid and playlist title\n",
    "                pid = playlist['pid']\n",
    "                title = normalize_title(playlist['name'])\n",
    "                \n",
    "                #Adding the playlist and playlist name i the Pid_playListName\n",
    "                Pid_playListName.append([pid, title])\n",
    "                \n",
    "                #Check if this playlist name exist in the cold_start_titles, if the name existing then extracting tracks from this \n",
    "                # mpd playlist to use these tracks for the cold start titles.\n",
    "                if title in cold_start_titles:\n",
    "                    for i, track in enumerate(playlist['tracks']):\n",
    "                        trackuri = track['track_uri']\n",
    "                        if title not in title_dict.keys():\n",
    "                            temp_dict = dict()\n",
    "                            temp_dict[trackuri] = 1\n",
    "                            title_dict[title] = temp_dict\n",
    "                        else:\n",
    "                            try:\n",
    "                                title_dict[title][trackuri] += 1\n",
    "                            except:\n",
    "                                title_dict[title][trackuri] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the pid and column name combination in the csv for analysis.\n",
    "Pid_nameDF = DataFrame(Pid_playListName,columns=['pid', 'name'])\n",
    "Pid_nameDF.to_csv('/Users/bijayani/Documents/MS/SEM3/CMPE256/Project/SmallerDataSet/TitleMatching/Pid_NameList')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough items to recommend!\n",
      "384 384\n",
      "Not enough items to recommend!\n",
      "423 423\n",
      "Not enough items to recommend!\n",
      "436 436\n",
      "Not enough items to recommend!\n",
      "251 251\n",
      "Not enough items to recommend!\n",
      "427 427\n",
      "Not enough items to recommend!\n",
      "127 127\n",
      "Not enough items to recommend!\n",
      "406 406\n",
      "Not enough items to recommend!\n",
      "313 313\n",
      "Not enough items to recommend!\n",
      "457 457\n",
      "Not enough items to recommend!\n",
      "441 441\n",
      "Not enough items to recommend!\n",
      "242 242\n",
      "Not enough items to recommend!\n",
      "95 95\n",
      "Not enough items to recommend!\n",
      "286 286\n",
      "Not enough items to recommend!\n",
      "402 402\n",
      "Not enough items to recommend!\n",
      "236 236\n",
      "Not enough items to recommend!\n",
      "55 55\n",
      "Not enough items to recommend!\n",
      "20 20\n",
      "Not enough items to recommend!\n",
      "450 450\n",
      "Not enough items to recommend!\n",
      "249 249\n",
      "Not enough items to recommend!\n",
      "70 70\n",
      "Not enough items to recommend!\n",
      "126 126\n",
      "Not enough items to recommend!\n",
      "106 106\n",
      "Not enough items to recommend!\n",
      "468 468\n",
      "Not enough items to recommend!\n",
      "400 400\n"
     ]
    }
   ],
   "source": [
    "#Append final_dict dictionary with the cold start titles and their respective tracks from the title_dict dictionary.\n",
    "for title, items in title_dict.items():\n",
    "        temp = []\n",
    "        for track in items.keys():\n",
    "            temp.append((track, items[track]))\n",
    "        temp.sort(key=operator.itemgetter(1), reverse=True)\n",
    "        temp1 = temp[:500]\n",
    "\n",
    "        mapped_recs = [val[0] for val in temp1]\n",
    "        #Notify if the mapped tracks for a title are less than 500 songs.\n",
    "        if len(mapped_recs) < 500:\n",
    "            print(\"Not enough items to recommend!\")\n",
    "            print(len(temp1), len(mapped_recs))\n",
    "        final_dict[title] = mapped_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the the cold start title recommendations into a csv file for using it for other base models.\n",
    "for title, recs in final_recs.items():\n",
    "        str_out = title\n",
    "        for rec in recs:\n",
    "            str_out += ',' + str(rec)\n",
    "        final_file.write(str_out + '\\n')\n",
    "        final_file.flush()\n",
    "final_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching the title similarity csv to check for the 1000 challenge dataset playlist \n",
    "title  = pd.read_csv('/Users/bijayani/Documents/MS/SEM3/CMPE256/Project/SmallerDataSet/TitleMatching/title_popularity_recs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(746, 501)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
