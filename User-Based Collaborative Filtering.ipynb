{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[.,\\/#!$%\\^\\*;:{}=\\_`~()@-]\", ' ', name)\n",
    "    name = re.sub(r\"&\", 'and', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "\n",
    "cold_start_recommendation = pd.read_csv('title_popularity_recs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_data():\n",
    "    #Save data from Columns of interest\n",
    "    playlist_col = ['num_tracks', 'pid']\n",
    "    tracks_col = ['album_uri', 'artist_name', 'artist_uri', \n",
    "                  'duration_ms', 'track_name', 'track_uri'] \n",
    "    playlist_test_col = ['name', 'num_holdouts', 'num_samples', 'num_tracks', 'pid']\n",
    "    \n",
    "    \n",
    "    #The million playlist data path\n",
    "    filenames = os.listdir('mpd/data/')\n",
    "    \n",
    "    #initialize the variables\n",
    "    data_playlists = []\n",
    "    data_tracks = []\n",
    "    playlists = []\n",
    "    tracks = set()\n",
    "    total_time = 0\n",
    "    \n",
    "    print(\"*****************************************************\")\n",
    "    print(\"Reading the slices containing playlists\")\n",
    "    for filename in tqdm(filenames):\n",
    "        fullpath = os.sep.join(('mpd//data/', filename))\n",
    "        f = open(fullpath)\n",
    "        js = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        #Load every slice\n",
    "        mpd_slice = json.loads(js)\n",
    "        \n",
    "        for playlist in mpd_slice['playlists']:\n",
    "            data_playlists.append([playlist[col] for col in playlist_col])\n",
    "            for track in playlist['tracks']:\n",
    "                playlists.append([playlist['pid'], track['track_uri'], track['pos']])\n",
    "                if track['track_uri'] not in tracks:\n",
    "                    data_tracks.append([track[col] for col in tracks_col])\n",
    "                    tracks.add(track['track_uri'])\n",
    "    gc.collect()\n",
    "    print(\"Reading the challenge dataset\")\n",
    "    f = open('challenge/challenge_set.json')\n",
    "    js = f.read()\n",
    "    f.close()\n",
    "    mpd_slice = json.loads(js)\n",
    "\n",
    "    data_playlists_test = []\n",
    "    playlists_test = []\n",
    "    print(len(tracks))\n",
    "    recs_cold_start= ['']\n",
    "    \n",
    "    #This is required for the online submission\n",
    "    first_line = 'team_info,team_name,main,your@email.com'\n",
    "    df_tracks_training = pd.DataFrame(data_tracks, columns=tracks_col)\n",
    "    with codecs.open('Submission_1.csv', \"w\") as o:\n",
    "        o.write(\"%s \\n\" %(first_line))\n",
    "        o.write(\"\\n\")\n",
    "    for playlist in tqdm((mpd_slice['playlists'])):       \n",
    "        for track in playlist['tracks']:\n",
    "            playlists_test.append([playlist['pid'], track['track_uri'], track['pos']])\n",
    "            if track['track_uri'] not in tracks:\n",
    "                data_tracks.append([track[col] for col in tracks_col])\n",
    "                tracks.add(track['track_uri'])\n",
    "        #Check if the challenge set contains any tracks\n",
    "        if(playlist['num_samples'] == 0):\n",
    "            name = playlist['name']\n",
    "            pid = playlist['pid']\n",
    "            name = normalize_name(name)\n",
    "            #Find the playlists with same titles\n",
    "            row = cold_start_recommendation[cold_start_recommendation['Names'] == name]\n",
    "            row = row.dropna(axis=1, how='all')\n",
    "            #If the title has 500 songs that can be recommended, add them to the final submission\n",
    "            if row.shape[1] == 501:\n",
    "                df_list = row.values.tolist()\n",
    "                df_list = df_list.pop()[1:]\n",
    "                with codecs.open('Submission_1.csv', \"a\") as o:\n",
    "                    o.write(\"%s\" %(pid) + ',')\n",
    "                    recs = ','.join(map(str, df_list))\n",
    "                    o.write(recs)\n",
    "                    o.write(\"\\n\")\n",
    "                    o.write(\"\\n\")\n",
    "                recs = ['']\n",
    "            else:  \n",
    "                #Add random 2 tracks as seed tracks\n",
    "                appendTracks = []\n",
    "                mTracks = {'album_uri':'x', 'artist_name' :'y', 'artist_uri':'x', \n",
    "                      'duration_ms':0, 'track_name ':'f', 'track_uri': 'spotify:track:67fNcOYgQ0jnEqcn7U4Mzo', 'pos':0}\n",
    "                mTracks1 = {'album_uri':'x', 'artist_name' :'y', 'artist_uri':'x', \n",
    "                      'duration_ms':0, 'track_name ':'f_1', 'track_uri': 'spotify:track:0GZoB8h0kqXn7XFm4Sj06k', 'pos':1}\n",
    "                appendTracks.append(mTracks)\n",
    "                appendTracks.append(mTracks1)\n",
    "                playlist['tracks'] = appendTracks\n",
    "                for track in playlist['tracks']:\n",
    "                    playlists.append([playlist['pid'], track['track_uri'], track['pos']])\n",
    "                    playlists_test.append([playlist['pid'], track['track_uri'], track['pos']])\n",
    "\n",
    "        data_playlists_test.append([playlist.get(col, '') for col in playlist_test_col])\n",
    "    #Store the data collected from playlists to dataframe           \n",
    "    df_playlists_info = pd.DataFrame(data_playlists, columns=playlist_col)\n",
    "    df_tracks = pd.DataFrame(data_tracks, columns=tracks_col)\n",
    "    df_tracks['tid'] = df_tracks.index\n",
    "\n",
    "    track_uri2tid = df_tracks.set_index('track_uri').tid\n",
    "\n",
    "    df_playlists = pd.DataFrame.from_records(playlists, columns=['pid', 'tid', 'pos'])\n",
    "    df_playlists.tid = df_playlists.tid.map(track_uri2tid)\n",
    "\n",
    "    df_playlists_test_info = pd.DataFrame.from_records(data_playlists_test, columns=playlist_test_col)\n",
    "\n",
    "    df_playlists_test = pd.DataFrame.from_records(playlists_test, columns=['pid', 'tid', 'pos'])\n",
    "    df_playlists_test.tid = df_playlists_test.tid.map(track_uri2tid)\n",
    "\n",
    "    print(\"df_tracks\")\n",
    "    print(df_tracks)\n",
    "    print(\"df_tracks_info\")\n",
    "    print(df_playlists)\n",
    "    print(\"df_playlists\")\n",
    "    print(df_playlists_info)\n",
    "    print(\"df_playlists_test\")\n",
    "    print(df_playlists_test)\n",
    "    print(\"df_playlists_test_info\")\n",
    "    print(df_playlists_test_info)\n",
    "    \n",
    "    #Store the dataframe in hdf files for further usage\n",
    "    df_tracks.to_hdf('hdf_files/tracks_info.hdf', key ='a')\n",
    "    df_playlists.to_hdf('hdf_files/tracks.hdf', key ='a')\n",
    "    df_playlists_info.to_hdf('hdf_files/playlists_info.hdf', key='a')\n",
    "    df_playlists_test.to_hdf('hdf_files/tracks_test.hdf', key='a')\n",
    "    df_playlists_test_info.to_hdf('hdf_files/playlists_test_info.hdf',key='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "*****************************************************\n",
      "Reading the slices containing playlists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:09<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the challenge dataset\n",
      "110716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:09<00:00, 1072.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_tracks\n",
      "                                   album_uri     artist_name  \\\n",
      "0       spotify:album:4S5MLjwRSi0NJ5nikflYnZ       AronChupa   \n",
      "1       spotify:album:1qHVYbxQ6IS8YRviorKDJI       AronChupa   \n",
      "2       spotify:album:4UEPxQx0cTcYNsE0n32MHV           Lorde   \n",
      "3       spotify:album:0rmhjUgoVa17LZuS8xWQ3v           Lorde   \n",
      "4       spotify:album:0rmhjUgoVa17LZuS8xWQ3v           Lorde   \n",
      "...                                      ...             ...   \n",
      "110711  spotify:album:6wNKjgN0Fo7jnOpAHXDLeF     Soft Swells   \n",
      "110712  spotify:album:4gCXFcJXBeseiCQ0GCakO0     Paper Route   \n",
      "110713  spotify:album:1NhFksWs1Nsz6wQI8ysTkv  Brandi Carlile   \n",
      "110714  spotify:album:1wgGprEG5HgYbhFq3eMmtO    Doom & Gloom   \n",
      "110715  spotify:album:1wgGprEG5HgYbhFq3eMmtO         Badwolf   \n",
      "\n",
      "                                   artist_uri  duration_ms  \\\n",
      "0       spotify:artist:5vCOdeiQt9LyzdI87kt5Sh       163809   \n",
      "1       spotify:artist:5vCOdeiQt9LyzdI87kt5Sh       166848   \n",
      "2       spotify:artist:163tK9Wjr9P9DmM0AVK7lm       232506   \n",
      "3       spotify:artist:163tK9Wjr9P9DmM0AVK7lm       216600   \n",
      "4       spotify:artist:163tK9Wjr9P9DmM0AVK7lm       193058   \n",
      "...                                       ...          ...   \n",
      "110711  spotify:artist:6GZtYGgIzJHSJsiV43qvuK       190679   \n",
      "110712  spotify:artist:2EoJ4ILZNAHjVtZgmWBaID       258546   \n",
      "110713  spotify:artist:2sG4zTOLvjKG1PSoOyf5Ej       196760   \n",
      "110714  spotify:artist:61l8LBmASmaPsm0q7rQF2i       203609   \n",
      "110715  spotify:artist:0auMOIcp6l7WqNOuBOwDcO       198400   \n",
      "\n",
      "                                               track_name  \\\n",
      "0                                            Little Swing   \n",
      "1                                        I'm an Albatraoz   \n",
      "2       Yellow Flicker Beat - From The Hunger Games: M...   \n",
      "3                                       White Teeth Teens   \n",
      "4                                                    Team   \n",
      "...                                                   ...   \n",
      "110711                                   Don't Cut it Off   \n",
      "110712                                              Sugar   \n",
      "110713                                Touching the Ground   \n",
      "110714                                     And I Love Her   \n",
      "110715                                      She Loves You   \n",
      "\n",
      "                                   track_uri     tid  \n",
      "0       spotify:track:66U0ASk1VHZsqIkpMjKX3B       0  \n",
      "1       spotify:track:5MhsZlmKJG6X5kTHkdwC4B       1  \n",
      "2       spotify:track:0GZoB8h0kqXn7XFm4Sj06k       2  \n",
      "3       spotify:track:35kahykNu00FPysz3C2euR       3  \n",
      "4       spotify:track:3G6hD9B2ZHOsgf4WfNu7X1       4  \n",
      "...                                      ...     ...  \n",
      "110711  spotify:track:72t49sR2ZMpMcGHstWJOeN  110711  \n",
      "110712  spotify:track:5LqkaUHOrOPt24RU5DfR7A  110712  \n",
      "110713  spotify:track:2zPaWxKdwaro3UmZ6ZVwfA  110713  \n",
      "110714  spotify:track:4P75K3ruHef0eP6GSJkncx  110714  \n",
      "110715  spotify:track:4W2YvWV0FuRnqPqnu9AlDf  110715  \n",
      "\n",
      "[110716 rows x 7 columns]\n",
      "df_tracks_info\n",
      "            pid    tid  pos\n",
      "0       1000000      0    0\n",
      "1       1000000      1    1\n",
      "2       1000000      2    2\n",
      "3       1000000      3    3\n",
      "4       1000000      4    4\n",
      "...         ...    ...  ...\n",
      "480965  1002557      2    1\n",
      "480966  1002589  48981    0\n",
      "480967  1002589      2    1\n",
      "480968  1002590  48981    0\n",
      "480969  1002590      2    1\n",
      "\n",
      "[480970 rows x 3 columns]\n",
      "df_playlists\n",
      "       num_tracks      pid\n",
      "0              11  1000002\n",
      "1              48  1000003\n",
      "2              40  1000004\n",
      "3              27  1000006\n",
      "4              41  1000007\n",
      "...           ...      ...\n",
      "12995         147     2995\n",
      "12996          24     2996\n",
      "12997         165     2997\n",
      "12998         158     2998\n",
      "12999          71     2999\n",
      "\n",
      "[13000 rows x 2 columns]\n",
      "df_playlists_test\n",
      "            pid    tid  pos\n",
      "0       1000047  48981    0\n",
      "1       1000047      2    1\n",
      "2       1000129  48981    0\n",
      "3       1000129      2    1\n",
      "4       1000165  48981    0\n",
      "...         ...    ...  ...\n",
      "281091  1006767  66241    0\n",
      "281092  1006771   3490    0\n",
      "281093  1006773  66242    0\n",
      "281094  1006775  17771    0\n",
      "281095  1006778   6339    0\n",
      "\n",
      "[281096 rows x 3 columns]\n",
      "df_playlists_test_info\n",
      "                  name  num_holdouts  num_samples  num_tracks      pid\n",
      "0     spanish playlist            11            0          11  1000002\n",
      "1              Groovin            48            0          48  1000003\n",
      "2               uplift            40            0          40  1000004\n",
      "3                 WUBZ            27            0          27  1000006\n",
      "4                  new            41            0          41  1000007\n",
      "...                ...           ...          ...         ...      ...\n",
      "9995     Playlist 2015            20            1          21  1006767\n",
      "9996           Workout            24            1          25  1006771\n",
      "9997             Girlz            16            1          17  1006773\n",
      "9998    let's get lost            35            1          36  1006775\n",
      "9999              Mama            28            1          29  1006778\n",
      "\n",
      "[10000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(__doc__)\n",
    "    create_df_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = pd.read_hdf('hdf_files/playlists_test_info.hdf') \n",
    "df_temp = playlists.loc[:,['num_tracks','pid']]\n",
    "df_temp = df_temp.set_index('pid')\n",
    "#Create a list with the playlist_ID and num_tracks in each playlist\n",
    "df_temp.to_hdf('hdf_files/df_playlist_test.hdf', key='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Song-Playlist and Playlist-Song Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data\n",
      "            pid    tid  pos\n",
      "0       1000000      0    0\n",
      "1       1000000      1    1\n",
      "2       1000000      2    2\n",
      "3       1000000      3    3\n",
      "4       1000000      4    4\n",
      "...         ...    ...  ...\n",
      "480965  1002557      2    1\n",
      "480966  1002589  48981    0\n",
      "480967  1002589      2    1\n",
      "480968  1002590  48981    0\n",
      "480969  1002590      2    1\n",
      "\n",
      "[480970 rows x 3 columns]\n",
      "testing_data\n",
      "            pid    tid  pos\n",
      "0       1000047  48981    0\n",
      "1       1000047      2    1\n",
      "2       1000129  48981    0\n",
      "3       1000129      2    1\n",
      "4       1000165  48981    0\n",
      "...         ...    ...  ...\n",
      "281091  1006767  66241    0\n",
      "281092  1006771   3490    0\n",
      "281093  1006773  66242    0\n",
      "281094  1006775  17771    0\n",
      "281095  1006778   6339    0\n",
      "\n",
      "[281096 rows x 3 columns]\n",
      "Building the song-playlist matrix for training set\n",
      "sp_train\n",
      "                                                     pid  \\\n",
      "tid                                                        \n",
      "0                                     [1000000, 1039848]   \n",
      "1      [1000000, 1009575, 1007292, 1010177, 1010328, ...   \n",
      "2      [1000047, 1000129, 1000165, 1000278, 1000281, ...   \n",
      "3      [1000000, 1001321, 1009736, 1023232, 1023474, ...   \n",
      "4      [1000000, 1001321, 1001521, 1006307, 1011992, ...   \n",
      "...                                                  ...   \n",
      "66238                                          [1006730]   \n",
      "66239                                          [1006741]   \n",
      "66240                                          [1006743]   \n",
      "66241                                          [1006767]   \n",
      "66242                                          [1006773]   \n",
      "\n",
      "                                                     pos  \n",
      "tid                                                       \n",
      "0                                               [0, 130]  \n",
      "1      [1, 2, 32, 40, 94, 87, 91, 14, 94, 63, 39, 129...  \n",
      "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "3             [3, 3, 4, 98, 13, 30, 90, 132, 56, 127, 0]  \n",
      "4      [4, 4, 2, 2, 7, 12, 13, 4, 16, 0, 36, 106, 19,...  \n",
      "...                                                  ...  \n",
      "66238                                                [0]  \n",
      "66239                                                [0]  \n",
      "66240                                                [0]  \n",
      "66241                                                [0]  \n",
      "66242                                                [0]  \n",
      "\n",
      "[66243 rows x 2 columns]\n",
      "Build song-playlist matrix for testing set\n",
      "sp_test\n",
      "                                                     pid  \\\n",
      "tid                                                        \n",
      "0                                     [1000000, 1039848]   \n",
      "1      [1000000, 1009575, 1007292, 1010177, 1010328, ...   \n",
      "2      [1000047, 1000129, 1000165, 1000278, 1000281, ...   \n",
      "3      [1000000, 1001321, 1009736, 1023232, 1023474, ...   \n",
      "4      [1000000, 1001321, 1001521, 1006307, 1011992, ...   \n",
      "...                                                  ...   \n",
      "66238                                          [1006730]   \n",
      "66239                                          [1006741]   \n",
      "66240                                          [1006743]   \n",
      "66241                                          [1006767]   \n",
      "66242                                          [1006773]   \n",
      "\n",
      "                                                     pos  \n",
      "tid                                                       \n",
      "0                                               [0, 130]  \n",
      "1      [1, 2, 32, 40, 94, 87, 91, 14, 94, 63, 39, 129...  \n",
      "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "3             [3, 3, 4, 98, 13, 30, 90, 132, 56, 127, 0]  \n",
      "4      [4, 4, 2, 2, 7, 12, 13, 4, 16, 0, 36, 106, 19,...  \n",
      "...                                                  ...  \n",
      "66238                                                [0]  \n",
      "66239                                                [0]  \n",
      "66240                                                [0]  \n",
      "66241                                                [0]  \n",
      "66242                                                [0]  \n",
      "\n",
      "[66243 rows x 2 columns]\n",
      "Build playlist-song matrix for training set\n",
      "                                                       tid  \\\n",
      "pid                                                          \n",
      "0        [1573, 4252, 4815, 7609, 571, 1318, 4795, 1079...   \n",
      "1        [1697, 66244, 66245, 66246, 66247, 66248, 6624...   \n",
      "2        [66259, 66260, 66261, 66262, 29808, 66263, 662...   \n",
      "3        [66289, 66290, 63238, 12498, 66291, 66292, 662...   \n",
      "4        [15667, 3982, 4511, 66376, 426, 1781, 2415, 70...   \n",
      "...                                                    ...   \n",
      "1049269  [65913, 65914, 2, 4480, 65915, 17166, 7964, 12...   \n",
      "1049300  [18199, 65937, 65938, 65939, 65940, 6609, 5178...   \n",
      "1049316  [65961, 5391, 24287, 17277, 4120, 46031, 5872,...   \n",
      "1049352  [21198, 66007, 19696, 20627, 1465, 1592, 24523...   \n",
      "1049360  [3458, 14726, 8617, 14728, 32742, 1559, 2529, ...   \n",
      "\n",
      "                                                       pos  \n",
      "pid                                                         \n",
      "0        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "1        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "2        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "3        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "4        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "...                                                    ...  \n",
      "1049269  [0, 1, 2, 3, 7, 11, 12, 14, 16, 18, 22, 24, 25...  \n",
      "1049300  [1, 3, 5, 6, 7, 8, 9, 12, 13, 16, 17, 19, 21, ...  \n",
      "1049316  [0, 1, 5, 8, 9, 11, 12, 15, 16, 18, 19, 21, 22...  \n",
      "1049352  [0, 1, 2, 3, 4, 5, 6, 13, 14, 15, 17, 19, 22, ...  \n",
      "1049360  [0, 1, 3, 4, 7, 8, 11, 12, 14, 17, 20, 21, 22,...  \n",
      "\n",
      "[12048 rows x 2 columns]\n",
      "Build playlist-song matrix for testing set\n",
      "                                                       tid  \\\n",
      "pid                                                          \n",
      "1000000                                    [0, 1, 2, 3, 4]   \n",
      "1000001  [15716, 15717, 15718, 15719, 1721, 15720, 1572...   \n",
      "1000009  [5233, 215, 15733, 15734, 15735, 1059, 7970, 1...   \n",
      "1000016                                    [5, 6, 7, 8, 9]   \n",
      "1000020                               [10, 11, 12, 13, 14]   \n",
      "...                                                    ...   \n",
      "1049269  [65913, 65914, 2, 4480, 65915, 17166, 7964, 12...   \n",
      "1049300  [18199, 65937, 65938, 65939, 65940, 6609, 5178...   \n",
      "1049316  [65961, 5391, 24287, 17277, 4120, 46031, 5872,...   \n",
      "1049352  [21198, 66007, 19696, 20627, 1465, 1592, 24523...   \n",
      "1049360  [3458, 14726, 8617, 14728, 32742, 1559, 2529, ...   \n",
      "\n",
      "                                                       pos  \n",
      "pid                                                         \n",
      "1000000                                    [0, 1, 2, 3, 4]  \n",
      "1000001  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "1000009  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "1000016                                    [0, 1, 2, 3, 4]  \n",
      "1000020                                    [0, 1, 2, 3, 4]  \n",
      "...                                                    ...  \n",
      "1049269  [0, 1, 2, 3, 7, 11, 12, 14, 16, 18, 22, 24, 25...  \n",
      "1049300  [1, 3, 5, 6, 7, 8, 9, 12, 13, 16, 17, 19, 21, ...  \n",
      "1049316  [0, 1, 5, 8, 9, 11, 12, 15, 16, 18, 19, 21, 22...  \n",
      "1049352  [0, 1, 2, 3, 4, 5, 6, 13, 14, 15, 17, 19, 22, ...  \n",
      "1049360  [0, 1, 3, 4, 7, 8, 11, 12, 14, 17, 20, 21, 22,...  \n",
      "\n",
      "[9048 rows x 2 columns]\n",
      "                                                       tid  \\\n",
      "pid                                                          \n",
      "0        [1573, 4252, 4815, 7609, 571, 1318, 4795, 1079...   \n",
      "1        [1697, 66244, 66245, 66246, 66247, 66248, 6624...   \n",
      "2        [66259, 66260, 66261, 66262, 29808, 66263, 662...   \n",
      "3        [66289, 66290, 63238, 12498, 66291, 66292, 662...   \n",
      "4        [15667, 3982, 4511, 66376, 426, 1781, 2415, 70...   \n",
      "...                                                    ...   \n",
      "1049269  [65913, 65914, 2, 4480, 65915, 17166, 7964, 12...   \n",
      "1049300  [18199, 65937, 65938, 65939, 65940, 6609, 5178...   \n",
      "1049316  [65961, 5391, 24287, 17277, 4120, 46031, 5872,...   \n",
      "1049352  [21198, 66007, 19696, 20627, 1465, 1592, 24523...   \n",
      "1049360  [3458, 14726, 8617, 14728, 32742, 1559, 2529, ...   \n",
      "\n",
      "                                                       pos  \n",
      "pid                                                         \n",
      "0        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "1        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "2        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "3        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "4        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "...                                                    ...  \n",
      "1049269  [0, 1, 2, 3, 7, 11, 12, 14, 16, 18, 22, 24, 25...  \n",
      "1049300  [1, 3, 5, 6, 7, 8, 9, 12, 13, 16, 17, 19, 21, ...  \n",
      "1049316  [0, 1, 5, 8, 9, 11, 12, 15, 16, 18, 19, 21, 22...  \n",
      "1049352  [0, 1, 2, 3, 4, 5, 6, 13, 14, 15, 17, 19, 22, ...  \n",
      "1049360  [0, 1, 3, 4, 7, 8, 11, 12, 14, 17, 20, 21, 22,...  \n",
      "\n",
      "[12048 rows x 2 columns]\n",
      "Saving the matrix Files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshi\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2434: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['pid', 'pos'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n",
      "C:\\Users\\joshi\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2434: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['tid', 'pos'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def main(argv):\n",
    "\n",
    "    training_data = pd.read_hdf('hdf_files/tracks.hdf')\n",
    "    testing_data = pd.read_hdf('hdf_files/tracks_test.hdf')\n",
    "    print(\"training_data\")\n",
    "    print(training_data)\n",
    "    print(\"testing_data\")\n",
    "    print(testing_data)\n",
    "    \n",
    "    tracks = pd.read_hdf('hdf_files/tracks.hdf')\n",
    "   \n",
    "    # Build playlist-song data for training and testing\n",
    "    print(\"Building the song-playlist matrix for training set\")\n",
    "    pid = testing_data.groupby(by='tid')['pid'].apply(list)\n",
    "    pos = testing_data.groupby(by='tid')['pos'].apply(list)\n",
    "    sp_train = pd.concat([pid,pos],axis=1)\n",
    "    print(\"sp_train\")\n",
    "    print(sp_train)\n",
    "      \n",
    "    \n",
    "    print(\"Build song-playlist data for testing set\")\n",
    "    pid = testing_data.groupby(by='tid')['pid'].apply(list)\n",
    "    pos = testing_data.groupby(by='tid')['pos'].apply(list)\n",
    "    sp_test = pd.concat([pid,pos],axis=1)\n",
    "    print(\"sp_test\")\n",
    "    print(sp_test)\n",
    "\n",
    " \n",
    "    tid = tracks.groupby(by='tid')['pid'].apply(list)\n",
    "    pos = tracks.groupby(by='tid')['pos'].apply(list)\n",
    "    sp_complete = pd.concat([tid,pos],axis=1)   \n",
    "    \n",
    "    \n",
    "    # Build playlist-song matrix\n",
    "    print(\"Build playlist-song data for training set\")\n",
    "    tid = training_data.groupby(by='pid')['tid'].apply(list)\n",
    "    pos = training_data.groupby(by='pid')['pos'].apply(list)\n",
    "    ps_train = pd.concat([tid,pos],axis=1)\n",
    "    print(ps_train)\n",
    "      \n",
    "    \n",
    "    print(\"Build playlist-song data for testing set\")\n",
    "    tid = testing_data.groupby(by='pid')['tid'].apply(list)\n",
    "    pos = testing_data.groupby(by='pid')['pos'].apply(list)\n",
    "    ps_test = pd.concat([tid,pos],axis=1)\n",
    "    print(ps_test)\n",
    "\n",
    "    \n",
    "    tid = tracks.groupby(by='pid')['tid'].apply(list)\n",
    "    pos = tracks.groupby(by='pid')['pos'].apply(list)\n",
    "    ps_complete = pd.concat([tid,pos],axis=1)    \n",
    "    print(ps_complete)\n",
    "    \n",
    "    print(\"Saving the Data Files\")\n",
    "        \n",
    "    sp_train.to_hdf(\"hdf_files/sp_train_new.hdf\",key='abc')\n",
    "    sp_test.to_hdf(\"hdf_files/sp_test_new.hdf\",key='abc')\n",
    "    sp_complete.to_hdf(\"hdf_files/sp_complete_new.hdf\",key='abc')\n",
    "    ps_train.to_hdf(\"hdf_files/ps_train_new.hdf\",key='abc')\n",
    "    ps_test.to_hdf(\"hdf_files/ps_test_new.hdf\",key='abc')\n",
    "    ps_complete.to_hdf(\"hdf_files/ps_complete_new.hdf\",key='abc')\n",
    "        \n",
    "if __name__ ==\"__main__\":\n",
    "    main(sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Playlist-Song Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       tid  \\\n",
      "pid                                                          \n",
      "0        [1573, 4252, 4815, 7609, 571, 1318, 4795, 1079...   \n",
      "1        [1697, 66244, 66245, 66246, 66247, 66248, 6624...   \n",
      "2        [66259, 66260, 66261, 66262, 29808, 66263, 662...   \n",
      "3        [66289, 66290, 63238, 12498, 66291, 66292, 662...   \n",
      "4        [15667, 3982, 4511, 66376, 426, 1781, 2415, 70...   \n",
      "...                                                    ...   \n",
      "1049269  [65913, 65914, 2, 4480, 65915, 17166, 7964, 12...   \n",
      "1049300  [18199, 65937, 65938, 65939, 65940, 6609, 5178...   \n",
      "1049316  [65961, 5391, 24287, 17277, 4120, 46031, 5872,...   \n",
      "1049352  [21198, 66007, 19696, 20627, 1465, 1592, 24523...   \n",
      "1049360  [3458, 14726, 8617, 14728, 32742, 1559, 2529, ...   \n",
      "\n",
      "                                                       pos  \n",
      "pid                                                         \n",
      "0        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "1        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "2        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "3        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "4        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
      "...                                                    ...  \n",
      "1049269  [0, 1, 2, 3, 7, 11, 12, 14, 16, 18, 22, 24, 25...  \n",
      "1049300  [1, 3, 5, 6, 7, 8, 9, 12, 13, 16, 17, 19, 21, ...  \n",
      "1049316  [0, 1, 5, 8, 9, 11, 12, 15, 16, 18, 19, 21, 22...  \n",
      "1049352  [0, 1, 2, 3, 4, 5, 6, 13, 14, 15, 17, 19, 22, ...  \n",
      "1049360  [0, 1, 3, 4, 7, 8, 11, 12, 14, 17, 20, 21, 22,...  \n",
      "\n",
      "[12048 rows x 2 columns]\n",
      "Number of PIDs in the testing data  9048  maximum Value  1049360\n",
      "Number of PIDs in the training data 12048  max  1049360\n",
      "num_tid  110716\n",
      "num_pid  12048\n",
      "Create rating matrix\n",
      "Saving the file\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import dok_matrix,save_npz,csc_matrix\n",
    "import argparse\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "def main():\n",
    "    \n",
    "    out_filename = \"playlist_song.pickle\"\n",
    "   \n",
    "    ps_train = pd.read_hdf(\"hdf_files/ps_train_new.hdf\")\n",
    "    print(ps_train)\n",
    "    sp_complete = pd.read_hdf(\"hdf_files/sp_complete_new.hdf\")\n",
    "    ps_complete = pd.read_hdf(\"hdf_files/ps_complete_new.hdf\")\n",
    "    ps_test = pd.read_hdf(\"hdf_files/ps_test_new.hdf\")\n",
    "    pid_list_complete = list(ps_complete.index)\n",
    "    pid_list_test= list(ps_test.index)\n",
    "    print(\"Number of PIDs in the testing data \", len(pid_list_test) , \" maximum Value \", max(pid_list_test))\n",
    "    print(\"Number of PIDs in the training data\", len(pid_list_complete) , \" max \", max(pid_list_complete))\n",
    "\n",
    "    # Get tid list\n",
    "    tid_list = list(sp_complete.index)\n",
    "    num_tid = len(tid_list)\n",
    "    print(\"num_tid \", num_tid)\n",
    "    dict_index = {k:v for k,v in zip(tid_list,range(0,num_tid))}\n",
    "\n",
    "    \n",
    "    # get pid list in train set\n",
    "    pid_list_train = list(ps_train.index)\n",
    "    num_pid = len(pid_list_train)\n",
    "    print(\"num_pid \", num_pid)\n",
    "    print(\"Create rating matrix\")\n",
    "    max_val_pid = max(max(pid_list_train),max(pid_list_test)) +1\n",
    "    max_val_tid = max(tid_list)+1\n",
    "    ps_matrix = dok_matrix((max_val_pid, max_val_tid), dtype=np.float32)\n",
    "    \n",
    "    del sp_complete\n",
    "    \n",
    "    for i in range(num_pid):\n",
    "        pid = pid_list_train[i]\n",
    "        tid = ps_train.loc[pid,'tid']\n",
    "        index_pid = pid\n",
    "        index_tid = [dict_index.get(i) for i in tid]\n",
    "        #Update the value to 1 if track present in the playlist\n",
    "        ps_matrix[index_pid,index_tid] = 1 \n",
    "\n",
    "    print(\"Saving the file\")\n",
    "    with open(out_filename, 'wb') as f:\n",
    "        pickle.dump(ps_matrix, f)    \n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Similarity Matrix for Playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the cosine similarity playlists\n",
      "Save similarity matrix playlist\n",
      "Build cosine similarity matrix for songs\n",
      "Save similarity matrix song\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as pp\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import dok_matrix,csc_matrix,csr_matrix,vstack\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool,Value\n",
    "import time\n",
    "import argparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity,paired_cosine_distances\n",
    "\n",
    "\n",
    "def cosine_similarities_playlist(pid_list_test,ps_matrix):\n",
    "    ps_matrix_norm = pp.normalize(ps_matrix, axis=1)\n",
    "    ps_matrix_test = ps_matrix_norm[pid_list_test,:]\n",
    "    return ps_matrix_test * ps_matrix_norm.T\n",
    "\n",
    "def cosine_similarities_song(index_tid_list_test,ps_matrix):\n",
    "    ps_matrix_norm = pp.normalize(ps_matrix, axis=0)\n",
    "    ps_matrix_test = ps_matrix_norm[:,index_tid_list_test]\n",
    "    return ps_matrix_test.T * ps_matrix_norm\n",
    "\n",
    "def main():\n",
    "\n",
    "    pickle_path = 'playlist_song.pickle'\n",
    "\n",
    "    with open(pickle_path,'rb') as f:\n",
    "        ps_matrix = pickle.load(f)      \n",
    "\n",
    "    #Convert to sparse matrix\n",
    "    ps_matrix_col = ps_matrix.tocsc() \n",
    "    ps_matrix_row = ps_matrix.tocsr()\n",
    "\n",
    "\n",
    "    sp_train = pd.read_hdf(\"hdf_files/sp_train_new.hdf\")\n",
    "    sp_test = pd.read_hdf(\"hdf_files/sp_test_new.hdf\")\n",
    "    ps_test = pd.read_hdf(\"hdf_files/ps_test_new.hdf\")\n",
    "    \n",
    "    \n",
    "    pid_list_test = list(ps_test.index)\n",
    "    print(\"Building the cosine similarity playlists\")\n",
    "    ps_sim_playlist = cosine_similarities_playlist(pid_list_test,ps_matrix_row)\n",
    "\n",
    "    print(\"Save similarity matrix playlist\")\n",
    "    \n",
    "    out_filename = \"cosineSimMatrix_playlist.pickle\"\n",
    "    \n",
    "    with open(out_filename, 'wb') as f:\n",
    "        pickle.dump(ps_sim_playlist, f,protocol=4)  \n",
    "        \n",
    "    # Get tid list\n",
    "    tid_list = list(sp_train.index)\n",
    "    num_tid = len(tid_list)\n",
    "    dict_index = {k:v for k,v in zip(tid_list,range(0,num_tid))}\n",
    "    tid_list_test = list(sp_test.index)\n",
    "    index_tid_list_test = [dict_index.get(i) for i in tid_list_test]\n",
    "    \n",
    "    print(\"Build cosine similarity matrix for songs\")\n",
    "    ps_sim_song = cosine_similarities_song(index_tid_list_test,ps_matrix_col)    \n",
    "    \n",
    "    print(\"Save similarity matrix song\")\n",
    "\n",
    "    out_filename = \"cosineSimMatrix_song.pickle\"\n",
    "    \n",
    "    with open(out_filename, 'wb') as f:\n",
    "        pickle.dump(ps_sim_song, f,protocol = 4)      \n",
    "    \n",
    "if __name__ ==\"__main__\":\n",
    "    main()\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Rating matrix\n",
      "Load Similarity Matrix\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import dok_matrix,csc_matrix\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from multiprocessing import Pool,Value\n",
    "import time\n",
    "\n",
    "pickle_path = 'playlist_song.pickle'\n",
    "\n",
    "print(\"Load Rating matrix\")\n",
    "with open(pickle_path,'rb') as f:\n",
    "    ps_matrix = pickle.load(f)      \n",
    "\n",
    "# Change to column sparse matrix because it is much faster to get column 12s -> 0.08s\n",
    "ps_matrix = ps_matrix.tocsc() \n",
    "\n",
    "\n",
    "\n",
    "print(\"Load Similarity Matrix\")\n",
    "sim_path = 'cosineSimMatrix_playlist.pickle'\n",
    "with open(sim_path,'rb') as f:\n",
    "    sim_matrix = pickle.load(f)      \n",
    "    \n",
    "# Change to column sparse matrix because it is much faster to get column 12s -> 0.08s\n",
    "sim_matrix = sim_matrix.tocsr()   \n",
    "\n",
    "#Generate 600 tracks\n",
    "num_of_tracks = 600\n",
    "\n",
    "def chunkify(lst,n):\n",
    "    return [lst[i::n] for i in range(n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Playlist and Song List\n",
      "9048 length of pid_list_test\n",
      "j  0\n",
      "j  1\n",
      "j  2\n",
      "j  3\n",
      "j  4\n",
      "j  5\n",
      "j  6\n",
      "j  7\n",
      "j  8\n",
      "j  9\n",
      "j  10\n",
      "j  11\n",
      "j  12\n",
      "j  13\n",
      "j  14\n",
      "Saving the test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshi\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2434: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['tid', 'pos'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    # Playlist-Song Matrix\n",
    "    ps_train = pd.read_hdf(\"hdf_files/ps_train_new.hdf\")\n",
    "    ps_test = pd.read_hdf(\"hdf_files/ps_test_new.hdf\")\n",
    "    sp_train = pd.read_hdf(\"hdf_files/sp_train_new.hdf\")\n",
    "    ps_test_1 = pd.read_hdf(\"hdf_files/ps_test_new.hdf\")   \n",
    "\n",
    "    print(\"Building Playlist and Song List\")\n",
    "    # Get tid list\n",
    "    tid_list = list(sp_train.index)\n",
    "    num_tid = len(tid_list)   \n",
    "    tid_index = list(np.arange(0,num_tid))\n",
    "    \n",
    "    # get pid list in training set\n",
    "    pid_list = list(ps_train.index)  \n",
    "    \n",
    "    # get pid list in test set\n",
    "    pid_list_test = list(ps_test.index)\n",
    "    print(len(pid_list_test), \"length of pid_list_test\")\n",
    "    \n",
    "    #Save the recommendations  \n",
    "    record = []\n",
    "    #Required if the training terminates in between on HPC\n",
    "#     df_read_ch_1 = pd.read_csv(\"Records.csv\")\n",
    "#     record = df_read_ch_1.values.tolist()\n",
    "#     print(\"length record\", len(record))\n",
    "\n",
    "    #Divide data in chunks\n",
    "    pid_list_test_divided = chunkify(pid_list_test, 15)\n",
    "    for j in range(len(pid_list_test_divided)):\n",
    "        iter_playlist = pid_list_test_divided[j]\n",
    "        print(\"j \", j)\n",
    "        for i in range(len(iter_playlist)):\n",
    "            pid = iter_playlist[i]\n",
    "            start = time.time()\n",
    "            vector1 = ps_test.loc[pid,'tid']\n",
    "            sim_vector_ = sim_matrix[i,:]     \n",
    "            norm = np.sum(sim_vector_)\n",
    "\n",
    "            rating = sim_vector_.dot(ps_matrix)       \n",
    "            rating = rating / norm\n",
    "\n",
    "            rating_array = rating.toarray()[0]\n",
    "            counter_list = list(enumerate(rating_array, 0))\n",
    "\n",
    "            # Filter songs already present in the training set\n",
    "            counter_list_filter = [(x,y) for x,y in counter_list if x not in vector1]\n",
    "\n",
    "            # Sort by rating\n",
    "            sortedList = sorted(counter_list_filter, key=lambda x:x[1],reverse=True)\n",
    "\n",
    "            new_tid = []\n",
    "            for i,_ in sortedList[:(num_of_tracks)]:\n",
    "                new_tid.append(i)\n",
    "            record.append(new_tid)\n",
    "#          Required for HPC\n",
    "        df = pd.DataFrame (record)\n",
    "#         print(\"*************************************************************\")\n",
    "#         print(\"Playlist Number saved\", j)\n",
    "        df.to_csv(\"Records.csv\")\n",
    "    \n",
    "#     print(\"Create new dataframe\")\n",
    "#     df_read_ch = pd.read_csv(\"Records.csv\")\n",
    "#     abd = df_read_ch.values.tolist()\n",
    "#     print(\"length record\", len(abd))\n",
    "    ps_test['tid'] = record\n",
    "    \n",
    "    print(\"Saving the test data\")\n",
    "    ps_test.to_hdf('hdf_files/ps_test_complete_CF_playlist.hdf', key='abc')\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Result to Submission file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_test_older = pd.read_hdf(\"hdf_files/tracks_test.hdf\")\n",
    "tid_org_list = ps_test_older.groupby(by='pid')['tid'].apply(list).reset_index(name = 'tid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid\n",
      "1000000    [48981, 1133, 6180, 1015, 1108, 1109, 499, 156...\n",
      "1000001    [1721, 11603, 6866, 11610, 15717, 15729, 11609...\n",
      "1000009    [1058, 643, 215, 7004, 1968, 1059, 15734, 1573...\n",
      "1000016    [7, 9, 8, 5, 1567, 3656, 574, 1132, 5807, 6, 4...\n",
      "1000020    [11, 12, 10, 13, 14, 4390, 3563, 275, 1739, 93...\n",
      "                                 ...                        \n",
      "1049269    [2470, 5873, 1354, 6466, 667, 3272, 2043, 1994...\n",
      "1049300    [1490, 404, 1491, 330, 1127, 4426, 5809, 2021,...\n",
      "1049316    [841, 1494, 1492, 13938, 5595, 1493, 1495, 843...\n",
      "1049352    [1500, 1498, 1195, 100, 1654, 6535, 8096, 3152...\n",
      "1049360    [117, 2474, 1940, 2630, 1930, 1502, 3834, 331,...\n",
      "Name: tid, Length: 9048, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tracks_info = pd.read_hdf(\"hdf_files/tracks_info.hdf\")\n",
    "ps_test = pd.read_hdf(\"hdf_files/ps_test_complete_CF_playlist.hdf\")\n",
    "\n",
    "ps_test.reset_index(drop=True)\n",
    "print(ps_test['tid'])\n",
    "\n",
    "pid_tid = ps_test['tid']\n",
    "\n",
    "pid_tid = pid_tid.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pid                                                tid\n",
      "0     1000000  [48981, 1133, 6180, 1015, 1108, 1109, 499, 156...\n",
      "1     1000001  [1721, 11603, 6866, 11610, 15717, 15729, 11609...\n",
      "2     1000009  [1058, 643, 215, 7004, 1968, 1059, 15734, 1573...\n",
      "3     1000016  [7, 9, 8, 5, 1567, 3656, 574, 1132, 5807, 6, 4...\n",
      "4     1000020  [11, 12, 10, 13, 14, 4390, 3563, 275, 1739, 93...\n",
      "...       ...                                                ...\n",
      "9043  1049269  [2470, 5873, 1354, 6466, 667, 3272, 2043, 1994...\n",
      "9044  1049300  [1490, 404, 1491, 330, 1127, 4426, 5809, 2021,...\n",
      "9045  1049316  [841, 1494, 1492, 13938, 5595, 1493, 1495, 843...\n",
      "9046  1049352  [1500, 1498, 1195, 100, 1654, 6535, 8096, 3152...\n",
      "9047  1049360  [117, 2474, 1940, 2630, 1930, 1502, 3834, 331,...\n",
      "\n",
      "[9048 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "print(pid_tid)\n",
    "\n",
    "recs = ['']\n",
    "tid_list_added = ['']\n",
    "\n",
    "tid_info = tracks_info[['tid', 'track_uri']]\n",
    "tid_info = tid_info.set_index('tid').track_uri\n",
    "\n",
    "\n",
    "with codecs.open('Submission_1.csv', \"a\") as o:\n",
    "    for index, row in pid_tid.iterrows():\n",
    "#         print(index)\n",
    "        pid = row['pid']\n",
    "#         print(\"pid \", pid)\n",
    "#         b = int(pid)\n",
    "        tid_list = row['tid']\n",
    "        list_tid = tid_org_list[tid_org_list['pid'] == pid]['tid']\n",
    "        a = []\n",
    "        for i in list_tid:\n",
    "            a.append(i) \n",
    "        \n",
    "        count = 0\n",
    "        for i in range(600):\n",
    "            if tid_list[i] not in tid_list_added and count<500 and tid_list[i] not in a[0]:\n",
    "                count += 1\n",
    "                tid_list_added.append(tid_list[i])\n",
    "                recs.append(tid_info[tid_list[i]])\n",
    "        o.write(\"%s\" %(pid))\n",
    "        recs = ','.join(map(str, recs))\n",
    "        o.write(recs)\n",
    "        o.write(\"\\n\")\n",
    "        o.write(\"\\n\")\n",
    "        tid_list_added = ['']\n",
    "        recs = ['']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref : https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge\n",
    "\"\"\"\n",
    "  Verifies that a given challenge submision is properly constructed.\n",
    "\n",
    "  Usage:\n",
    "\n",
    "        python verify_submission.py challenge_set.json submission.csv\n",
    "\"\"\"\n",
    "import sys\n",
    "import json\n",
    "\n",
    "NTRACKS = 500\n",
    "\n",
    "\n",
    "def verify_submission(challenge_path, submission_path):\n",
    "    has_team_info = False\n",
    "    error_count = 0\n",
    "\n",
    "    try:\n",
    "        f = open(challenge_path)\n",
    "        js = f.read()\n",
    "        f.close()\n",
    "        challenge = json.loads(js)\n",
    "    except FileNotFoundError:\n",
    "        error_count += 1\n",
    "        print(\"Can't read the challenge set\")\n",
    "        return error_count\n",
    "\n",
    "    pids = set([playlist[\"pid\"] for playlist in challenge[\"playlists\"]])\n",
    "    if len(challenge[\"playlists\"]) != 10000:\n",
    "        print(\"Bad challenge set\")\n",
    "        error_count += 1\n",
    "\n",
    "    # seed_tracks contains seed tracks for each challenge playlist\n",
    "    seed_tracks = {}\n",
    "    for playlist in challenge[\"playlists\"]:\n",
    "        track_uris = [track[\"track_uri\"] for track in playlist[\"tracks\"]]\n",
    "        seed_tracks[playlist[\"pid\"]] = set(track_uris)\n",
    "\n",
    "    found_pids = set()\n",
    "\n",
    "    if error_count > 0:\n",
    "        return error_count\n",
    "\n",
    "    f = open(submission_path)\n",
    "    for line_no, line in enumerate(f):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line[0] == \"#\":\n",
    "            continue\n",
    "\n",
    "        if not has_team_info:\n",
    "            if line.startswith(\"team_info\"):\n",
    "                has_team_info = True\n",
    "                tinfo = line.split(\",\")\n",
    "            else:\n",
    "                print(\"missing team_info at line\", line_no)\n",
    "                error_count += 1\n",
    "\n",
    "        else:\n",
    "            fields = line.split(\",\")\n",
    "            fields = [f.strip() for f in fields]\n",
    "            try:\n",
    "                pid = int(fields[0])\n",
    "            except ValueError:\n",
    "                print(\"bad pid (should be an integer)\", fields[0], \"at line\", line_no)\n",
    "                error_count += 1\n",
    "                continue\n",
    "            tracks = fields[1:]\n",
    "            found_pids.add(pid)\n",
    "            if not pid in pids:\n",
    "                print(\"bad pid\", pid, \"at line\", line_no)\n",
    "                error_count += 1\n",
    "            if len(tracks) != NTRACKS:\n",
    "                print(\n",
    "                    \"wrong number of tracks, found\",\n",
    "                    len(tracks),\n",
    "                    \"should have\",\n",
    "                    NTRACKS,\n",
    "                    \"at\",\n",
    "                    line_no,\n",
    "                )\n",
    "                error_count += 1\n",
    "            if len(set(tracks)) != NTRACKS:\n",
    "                print(\n",
    "                    \"wrong number of unique tracks, found\",\n",
    "                    len(set(tracks)),\n",
    "                    \"should have\",\n",
    "                    NTRACKS,\n",
    "                    \"at\",\n",
    "                    line_no,\n",
    "                )\n",
    "                error_count += 1\n",
    "\n",
    "            if seed_tracks[pid].intersection(set(tracks)):\n",
    "                print(\n",
    "                    \"found seed tracks in the submission for playlist\",\n",
    "                    pid,\n",
    "                    \"at\",\n",
    "                    line_no,\n",
    "                )\n",
    "                error_count += 1\n",
    "\n",
    "            for uri in tracks:\n",
    "                if not is_track_uri(uri):\n",
    "                    print(\"bad track uri\", uri, \"at\", line_no)\n",
    "                    error_count += 1\n",
    "\n",
    "    if len(found_pids) != len(pids):\n",
    "        print(\n",
    "            \"wrong number of playlists, found\", len(found_pids), \"expected\", len(pids)\n",
    "        )\n",
    "        error_count += 1\n",
    "\n",
    "    return error_count\n",
    "\n",
    "\n",
    "def is_track_uri(uri):\n",
    "    fields = uri.split(\":\")\n",
    "    return (\n",
    "        len(fields) == 3\n",
    "        and fields[0] == \"spotify\"\n",
    "        and fields[1] == \"track\"\n",
    "        and len(fields[2]) == 22\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"usage: python verify_submission.py challenge_set.json submission.csv\")\n",
    "        sys.exit()\n",
    "    errors = verify_submission(\"challenge/challenge_set.json\", \"Submission_1.csv\")\n",
    "    if errors == 0:\n",
    "        print(\n",
    "            \"Submission is OK! Remember to gzip your submission before submitting it to the challenge.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"Your submission has\",\n",
    "            errors,\n",
    "            \"errors. If you submit it, it will be rejected.\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
